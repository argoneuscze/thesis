LLVM \cite{Lattner:MSThesis02}, formerly known as \emph{Low-Level Virtual Machine} is "a collection of modular and reusable compiler and toolchain technologies" \cite{llvm_web}. Originally intended as a compiler infrastructure well-suited for modern programming languages, it has since grown into an umbrella term for a decently large group of sub-projects, intended for building everything related to compilers, that is frontends, backends, optimizers, Just-In-Time compilers etc. Some of these sub-projects will be discussed later in the chapter.

Today, LLVM is a popular choice for TODO

This work will be using LLVM and its toolset exclusively.

\section{Structure}
Written in C++, at its core LLVM uses a classical three phase compilation process \cite{Lattner:LLVM_Design}, popular for static compilers. These three phases are namely the frontend, optimizer, and backend.

The frontend is responsible for parsing and validating the source code, generally producing some sort of intermediate form. The optimizer then takes this form, and does various transformations to improve the code's running time, and is mostly independent of the target. Finally, the backend generates actual machine code specific to the architecture.

The main benefit of this design is that a programmer writing source code doesn't need to worry about architecture specific assembly code or optimizations, and one code should work the same on every platform supported by the backend.

\section{Intermediate Representation}
As I have mentioned in the previous section, all three phases during compilation work with some sort of intermediate code. In LLVM this internal assembly language is called \emph{Intermediate Representation} \cite{llvm_ir} (\emph{LLVM IR} for short, or just \emph{IR}), and it's arguably one of the most important parts of LLVM.

LLVM IR is a well specified SSA (Static Single Assignment) based representation that provides type safety and various low-level operations. It is the only interface to LLVM's optimizer and is used throughout all phases of LLVM's compilation process.

There are three different forms of LLVM IR, all of which are equivalent:
\begin{itemize}
	\item in-memory compiler IR
	\item on-disk bitcode representation (e.g. for JIT)
	\item a human readable assembly representation
\end{itemize}

The ability to have human readable IR is going to be extremely helpful, as it allows the developer to write or edit arbitrary IR and compile it to an executable file. This is difficult to do with other compilers, e.g. GCC's \emph{Gimple} only allows printing its intermediate form, but you cannot trivially edit and compile it to a functioning program.

I am not going to go into large detail here regarding the exact structure of a well-formed IR module, but having an overview is going to be necessary for understanding the implementation.

\subsection{Module}
An LLVM program is composed of one or more modules, which represent a translation unit of the input files. Modules consist of functions, global variables and symbol table entries. These module files can be further merged together (along with symbol resolution etc.) using the LLVM linker, but that's not required.

Incidentally, the module level is where most of the current optimizations run on. That is, if you want to run a certain transformation pass on a function, the easiest solution is to use the \texttt{opt} tool and run it on the whole module.

\subsection{Function}
A function is normally a callable piece of code that returns some value, and in IR they are no different. Similarly to C, functions in IR consist of a definition and a declaration.

Function definition uses the \texttt{define} keyword, and specifies a number of parameters. These, among others, include visibility style, calling convention, parameter list, return type, a function name, optional function attributes, metadata, and a list of basic blocks.

Declarations are a bit more lightweight. They use the \texttt{declare} keyword, and share many parameters with function definitions, though they miss the actual bulk of the function, that is things such as basic blocks, attributes or metadata.

\subsubsection{Attributes}
Function attributes are used to describe additional information about a function. They are part of the definition, but not the declaration. Attributes are part of the function itself, not its type, therefore different functions can be of the same type, but have different attributes.

Attributes will be used extensively throughout this work, as it is the most convenient way to communicate function-wide information to the optimizer. For example LLVM currently uses attributes to tell whether a function should be inlined or not.

To use a function attribute in the IR, it is generally a keyword (or a list of keywords, space separated) placed after the function type specified.

\subsection{Basic Block}
Basic blocks are the foundation of functions, forming the Control Flow Graph (CFG) of the containing function.

Each basic block contains a list of instructions, ending with a terminator function (e.g. branch or return). At the top of a basic block there can optionally be a label, giving this basic block a symbol table entry. If this label is not provided, it's automatically assigned one.

A special case of a basic block is the first basic block of any given function. It is immediately executed upon entrance into the function, and it may not have any predecessors (i.e. branches into this basic block from another one).

\subsection{Instruction}
Each basic block is composed of different instructions. Memory allocation, stores, loads, unary/binary instructions, terminators. It is not necessary to go into detail for every single one, but for this work, the important part about instructions are metadata.

\subsubsection{Metadata}
Every instruction can have different metadata attached to it, which will be used extensively in my implementation. Metadata is commonly used inside LLVM for hinting the code generator and optimizer, for example whether a loop should be unrolled and how much.

Metadata doesn't have a type, nor is it a value. There are two different types of metadata: strings and nodes.

Metadata strings are simple strings surrounded by double quotes, which can contain any (even non-printable) character. This is useful for setting various flags on an instruction.

Metadata nodes are similar, but other than a string they may also contain values. This is useful when you want to pass a specific parameter to an instruction, e.g. how many times a loop should be unrolled.

\section{Clang}
Clang \cite{llvm_clang} is part of the LLVM project and it's their frontend for C, C++, Objective-C and Objective-C++. It's integrated directly into the LLVM source code as a tool, making it easy to do and test any changes.

I will be using Clang to help produce customized IR to convey information to the optimizer and backend.

\section{Compilation process}
[insert picture here]

A standard compilation process can be described in a few steps.

First, the frontend (in our case Clang) parses the source code and produces an AST (Abstract Syntax Tree), which is then converted into LLVM IR.

This IR is then fed into the optimizer, which is a series of analysis and optimization passes. Depending on the optimization level, some, if not all of them, could be skipped. The result of this optimization is also IR, now hopefully running faster, taking less space, or both.

After we have the optimized IR, the code generator processes it. For each IR instruction or a sequence of instructions, it emits native machine code for the given target architecture, producing an executable program.

This is just the simplest procedure. There are more advanced things LLVM is capable of, such as link-time optimizations, which let LLVM optimize across e.g. file boundaries, by producing IR bitcode instead of native object files, letting LLVM aggregate them together and optimize a larger chunk.